---
permalink: /

author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Atrisha Sarkar heads the [Humans and Autonomous Agents Lab](https://www.uwoagentslab.ca) at Western University. She is an Assistant Professor in the Department of Electrical and Computer Engineering (Software Engineering) at [Western University](https://uwo.ca), Canada, faculty member of the [The Rotman Institute of Philosophy](https://www.rotman.uwo.ca/), and a Faculty Affiliate at [Schwartz Reisman Institute for Technology and Society](https://srinstitute.utoronto.ca). Her research focuses on **human-centric multiagent systems**, combining methods from empirical/behavioral game theory, software engineering, human-AI and human-robot interaction. The goal of this research is to design automated AI systems that prioritize safety and reliability in AI-based applications, ultimately ensuring the well-being of individual users and society as a whole.

---
# News

**(June 2025)**: New lab website launched for [Humans and Autonomous Agents Lab](https://www.uwoagentslab.ca)

**(Career update)**: Joining as a TT faculty in the Department of Electrical and Computer Engineering at Western Univeristy starting Jan, 2025.

**(Summer 2024)** I will be at the following conferences/workshops over the summer: CHAI @ Asilomar, California; SIOE @ UChicago; EC @ Yale. Please feel free to say Hi! if you are attending any of these and would like to chat.

**(May 2024)** New paper! Drawing from human social structures of norms and institutions, our new paper shows how to design LLM-based generative agents that have capacity for cooperative behaviour. [Link](https://arxiv.org/abs/2405.19328)

**(Feb 2024)** New paper out on arxiv with insights on opinion and rhetoric expression in online social systems. <br>
_Main takeaway:_ When there is ideological polarization within a population, ideological institutions (e.g., partisan media) can distort beliefs about the outgroup population to move the expressed opinion to one extreme. Affective polarization is a by-product of this dynamic. In other words, "Institutions matter" - in online social systems too. [Arxiv](https://arxiv.org/abs/2403.06264)

**(Sep 2023)** Attended the NBER Economics of Artificial Intelligence Conference, Fall 2023. Toronto. Canada.

**(Aug 2023)** I will be at the annual conference of the Society for Institutional and Organizational Economics (SIOE) *workshoping* our paper on norms and information stewarding. Frankfurt, Germany.

**(July 2023)** I gave an invited talk at Cooperative AI foundation on normative systems as a research agenda for cooperative AI foundation. London, UK. [Slides](https://www.dropbox.com/scl/fi/xuzibe27s5e7k51isp387/Atrisha_CAIF_retreat_presentation.pdf?rlkey=93r6guwmf5vir5ivxb74of1rt&dl=0)

**(June 2023)** I will be at CHAI (Center for Human-Compatible Artificial Intelligence) workshop in California, USA.

**(May-June 2023)** I will be at AAMAS 2023 in London, UK.

**(Feb 2023)** New [working paper](https://www.dropbox.com/s/zgf2hyizmgyfum8/Normative_information_design_for_online_social_systems_2.pdf?dl=0) on information stewards and normative persuasion in online social systems.

**(Dec 2022)** Our paper *Revealed multi-objective utility aggregation in human driving* (with Kate Larson and Krzysztof Czarnecki) accepted for AAMAS 2023.

**(Feb 2022)** Starting Sept'22 I will be joining [Schwartz Reisman Institute for Technology and Society](https://srinstitute.utoronto.ca
) at University of Toronto as a postdoctoral fellow under Prof. Gillian Hadfield.

**(Jan 2022)** Our paper *I  Know You Can't See Me: Dynamic Occlusion-Aware Safety Validation of  Strategic Planners for Autonomous Vehicles Using Hypergames* (with Maximilian Kahn and Krzysztof Czarnecki) accepted for ICRA 2022.

**(Dec 2021)** Our paper *Generalized dynamic cognitive hierarchy models for strategic driving behavior* (with Kate Larson and Krzysztof Czarnecki) accepted for AAAI 2022.

**(Oct 2021)** Paper on a taxonomy towards better understanding of decisions made by an autonomous vehicle planner. *A taxonomy of strategic human interactions in traffic conflicts* [arXiv link](https://arxiv.org/pdf/2109.13367) accepted for NeurIPS 2021 Cooperative AI Workshop.

**(Sept 2021)** Paper on application of general theories of behavioral game theory, such as level-k,   for dynamic games. *Generalized dynamic cognitive hierarchy models for strategic driving behavior* [arXiv link](https://arxiv.org/pdf/2109.09861) [code](https://git.uwaterloo.ca/a9sarkar/repeated_driving_games)

**(Sept 2021)** Paper on white-box safety validation framework for AV strategic planners (joint work with Maximilian Kahn). *I  Know You Can't See Me: Dynamic Occlusion-Aware Safety Validation of  Strategic Planners for Autonomous Vehicles Using Hypergames*  [arXiv link](https://arxiv.org/pdf/2109.09807) [video](https://youtu.be/-crio3rA_IU)

**(Aug 2021)** Waterloo Multi-Agent (WMA) Traffic Dataset released.  [Dataset](http://wiselab.uwaterloo.ca/waterloo-multi-agent-traffic-dataset/)

**(July 2021)** Talk on solving hierarchical games using solution concepts from behavioral game theory and application to human driving behavior.

**(March 2021)** Paper on *Solution Concepts in Hierarchical Games under Bounded Rationality with Applications to Autonomous Driving* published in AAAI'21 [paper](https://ojs.aaai.org/index.php/AAAI/article/view/16715) [code](https://git.uwaterloo.ca/a9sarkar/traffic_behavior_modeling)

